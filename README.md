## Goals 
- Use SFrames to do some feature engineering.
- Modify the decision trees to incorporate weights.
- Implement Adaboost ensembling.
- Use your implementation of Adaboost to train a boosted decision stump ensemble.
- Evaluate the effect of boosting (adding more decision stumps) on performance of the model.
- Explore the robustness of Adaboost to overfitting.

## Packages used 
- graphlab
- matplotlib

## Used data set 
[lending-club-data.gl](link to the data you upload)

# Algorithms used :
-  decision trees.
-  Adaboost ensembling.
-  boosted decision stump ensemble.